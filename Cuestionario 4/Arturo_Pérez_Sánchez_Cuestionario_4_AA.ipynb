{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master Universitario en Lógica, Computación e Inteligencia Artificial\n",
    "## Aprendizaje Automático\n",
    "**Autor:** Arturo Pérez Sánchez &nbsp;&nbsp;&nbsp;\n",
    "## Cuestionario 4: implementación de árboles de decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contenido\n",
    "\n",
    "1. <a href=\"#ej1\">Reproducción los pasos que se han visto en clase sobre el conjunto iris</a> <br>\n",
    "    1.a - <a href=\"#ej1-a\"> Carga del fichero y preprocesamiento </a> <br>\n",
    "    1.b - <a href=\"#ej1-b\"> examen exploratorio </a> <br>\n",
    "    1.c - <a href=\"#ej1-c\"> División del dataset y creación del árbol </a> <br>\n",
    "    1.d - <a href=\"#ej1-d\"> Representación gráfica del árbol </a> <br>\n",
    "    1.e - <a href=\"#ej1-e\"> Medidas de rendimiento sobre conjuntos de entrenamiento, prueba y total </a> <br>\n",
    "\n",
    "2. <a href=\"#ej2\"> Análisis adicional </a> <br>\n",
    "    2.a -  <a href=\"#ej2-a\"> Validación cruzada </a> <br>\n",
    "    2.b -  <a href=\"#ej2-b\"> Optimización de parámetros con SearchGrid </a> <br>\n",
    "    2.c -  <a href=\"#ej2-c\"> Simplificación del modelo </a> <br>\n",
    "    2.d -  <a href=\"#ej2-d\"> Árbol ID3 </a> <br>\n",
    "    2.e -  <a href=\"#ej2-e\"> Matriz de confusión </a> <br>\n",
    "    2.f -  <a href=\"#ej2-f\"> Otras métricas </a> <br>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el desarrollo de este proyecto había que utilizar un dataset del repositorio de la Universidad de California, por lo que tras probar con varios, me he decidido por utilizar el dataset <a href=\"https://archive.ics.uci.edu/ml/datasets/Early+stage+diabetes+risk+prediction+dataset.\"> Early stage diabetes risk prediction dataset </a>. Con estos datos intentaremos clasificar si un paciente tiene o no diabetes en función de varios parámetros<br><br>\n",
    "Este dataset consta de 520 filas (instancias) y 17 columnas (atributos). <br><br>\n",
    "\n",
    "# 1 Reproducción los pasos que se han visto en clase sobre el conjunto iris <a name=\"ej1\"> </a>\n",
    "\n",
    "Lo primero que tenemos que hacer antes de comenzar el análisis exploratorio es importar todas las librerias necesarias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_text\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import sklearn.metrics\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as skm\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez importadas todas las dependencias necesarias podemos comenzar con el primer punto: \n",
    "\n",
    "### 1.a) Carga del fichero y preprocesamiento <a name=\"ej1-a\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como el repositorio de la universidad de California nos ofrece los datos ya en formato .csv podemos leer directamente los datos desde la url:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/00529/diabetes_data_upload.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez cargado el dataset podemos imprimirlo en pantalla para ver los atributos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, todos los atributos a excepción de la edad son de tipo categórico, pero el algoritmo que vamos a utilizar necesita valores numéricos, por ello lo primero que vamos a hacer es manipular los datos para convertirlos a valores enteros, como los atributos son binarios, sustituiremos el valor \"Yes\" por 1 y \"No\" por 0.\n",
    "\n",
    "Cabe destacar que la variable que queremos predecir es \"class\" que tambien convertiremos a valores de tipo entero (1 para positivo y 0 para negativo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Gender'] = dataset['Gender'].map({'Male':1 ,'Female':0})\n",
    "dataset['Polyuria'] = dataset['Polyuria'].map({'Yes':1 ,'No':0})\n",
    "dataset['Polydipsia'] = dataset['Polydipsia'].map({'Yes':1 ,'No':0})\n",
    "dataset['sudden weight loss'] = dataset['sudden weight loss'].map({'Yes':1 ,'No':0})\n",
    "dataset['weakness'] = dataset['weakness'].map({'Yes':1 ,'No':0})\n",
    "dataset['Polyphagia'] = dataset['Polyphagia'].map({'Yes':1 ,'No':0})\n",
    "dataset['Genital thrush'] = dataset['Genital thrush'].map({'Yes':1 ,'No':0})\n",
    "dataset['visual blurring'] = dataset['visual blurring'].map({'Yes':1 ,'No':0})\n",
    "dataset['Itching'] = dataset['Itching'].map({'Yes':1 ,'No':0})\n",
    "dataset['Irritability'] = dataset['Irritability'].map({'Yes':1 ,'No':0})\n",
    "dataset['delayed healing'] = dataset['delayed healing'].map({'Yes':1 ,'No':0})\n",
    "dataset['partial paresis'] = dataset['partial paresis'].map({'Yes':1 ,'No':0})\n",
    "dataset['muscle stiffness'] = dataset['muscle stiffness'].map({'Yes':1 ,'No':0})\n",
    "dataset['Alopecia'] = dataset['Alopecia'].map({'Yes':1 ,'No':0})\n",
    "dataset['Obesity'] = dataset['Obesity'].map({'Yes':1 ,'No':0})\n",
    "\n",
    "# Atributo que queremos predecir\n",
    "dataset['class'] = dataset['class'].map({'Positive':1 ,'Negative':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a continuación separamos del dataset la clase que queremos clasificar de las demás y las guardamos en una variable separada (y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = dataset['class'].to_numpy()\n",
    "dataset = dataset.drop('class', axis=1)\n",
    "X_data = dataset.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.b) Examen exploratorio <a name=\"ej1-b\"> </a>\n",
    "\n",
    "Ahora vamos a realizar un pequeño análisis exploratorio del dataset, comenzamos representando la _scatter matrix_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = pd.plotting.scatter_matrix(dataset, c=y_data, figsize=(15, 15), marker='o',\n",
    "                                 hist_kwds={'bins': 20}, s=60, alpha=.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como la mayoria de atributos son binarios, es normal que los puntos aparezcan siempre en las esquinas, además podemos observar que el único atributo que no es categórico es el primero (la edad).<br>\n",
    "A continuación representaremos un mapa de calor con los coeficientes de **correlación de Pearson**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.title('Coeficiente de Correlación de Pearson entre los atributos', y=1.05, size=15)\n",
    "sns.heatmap(dataset.astype(float).corr(),linewidths=0.1,vmax=1.0, \n",
    "            square=True, cmap='viridis', linecolor='white', annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.c) División del dataset y creación del árbol <a name=\"ej1-c\"> </a>\n",
    "\n",
    "Primero dividiremos nuestro dataset en conjunto de test y de entrenamiento, concretamente repartiremos un 70% de entrenamiento y un 30% de test, además, crearemos una semilla para los datos no varíen con cada ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 5382\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data,y_data,test_size = 0.30, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez separados los datos ya podemos crear el árbol de decisión y entrenarlo con los datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = DecisionTreeClassifier(random_state=seed)\n",
    "modelo.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.d) Representación gráfica del árbol <a name=\"ej1-d\"> </a>\n",
    "\n",
    "Una vez hemos entrenado el árbol podemos utilizar la ibrería graphviz para representar gráficamente en árbol:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_graphviz(modelo, out_file='salida.dot', feature_names=dataset.columns, rounded=True, filled=True)\n",
    "with open(\"salida.dot\") as f:\n",
    "    grafo = f.read()\n",
    "graphviz.Source(grafo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puede verse al representar el árbol, hay muchos nodos que se crean para clasificar muy pocos datos, esto podría ser un posible caso de overfitting, en el siguiente apartado estudiaremos el rendimiento con los datos de tests que habiamos separado inicialmente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.d) Medidas de rendimiento sobre conjuntos de entrenamiento, prueba y total<a name=\"ej1-e\"> </a>\n",
    "\n",
    "Para evaluar el rendimiento del árbol generado podemos utilizar la medida de rendimiento _score_ que trae sklearn implementada, además guardaremos los resultados en un dataframe para compararlo con otros modelos que desarrollaremos en el ejercicio 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTADOS = pd.DataFrame(columns=['Train_performance', 'Test_performance','Total_performance'])\n",
    "\n",
    "RESULTADOS.loc['modelo'] = [modelo.score(X_train,y_train), modelo.score(X_test,y_test),  modelo.score(X_data,y_data)]\n",
    "RESULTADOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Análisis adicional <a name=\"ej2\"> </a>\n",
    "### 2.a) Validación cruzada <a name=\"ej2-a\"> </a>\n",
    "Lo primero que vamos a realizar sobre el modelo anterior es cambiar la forma de evaluarlo, por lo que en lugar de dividir el conjunto de datos en entrenamiento y test, utilizaremos validación cruzada (con 25 \"carpetas\") con estratificación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation = StratifiedKFold(n_splits = 25, shuffle = True, random_state =seed)\n",
    "scores = cross_val_score(modelo, X_data, y_data, scoring = \"accuracy\", cv = cross_validation)\n",
    "\n",
    "print( \"Exactitud (accuracy): %0.5f (+/- %0.5f)\" % (scores.mean(), scores.std() * 2) )\n",
    "\n",
    "RESULTADOS.loc['modelo + CV'] = ['N/A', 'N/A',  scores.mean()]\n",
    "RESULTADOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.b) Optimización de parámetros con SearchGrid <a name=\"ej2-b\"> </a>\n",
    "\n",
    "Otro de las cosas que podemos hacer es buscar los mejores valores para varios parámetros a la vez utilizando [SearchGrid](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'criterion':['gini', 'entropy'],\n",
    "    'max_depth':[None, 5, 10, 15],\n",
    "    'max_features':['auto', 'sqrt', 'log2'],\n",
    "    'max_leaf_nodes':[None, 25, 50],\n",
    "    'min_impurity_decrease':[0.0, 0.001, 0.01],\n",
    "    'min_samples_leaf':[8, 10, 12, 14],\n",
    "    'min_samples_split':[2, 15, 30, 45]\n",
    "}\n",
    "\n",
    "modelo_opt = GridSearchCV(DecisionTreeClassifier(random_state=seed), parameters, cv = cross_validation, n_jobs=2, scoring='accuracy')\n",
    "modelo_opt.fit(X_data, y_data)\n",
    "print('Mejores hiperparámetros encontrados:', modelo_opt.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RESULTADOS.loc['modelo_opt'] = [modelo_opt.score(X_train,y_train), modelo_opt.score(X_test,y_test),  modelo_opt.score(X_data,y_data)]\n",
    "RESULTADOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque parezca que utilizando los atributos óptimos se obtiene un resultado peor esto no es cierto, esto ocurre porque el primer modelo se están evaluando perfectamente todos los atributos del set de entrenamiento, lo que hace que el rendimiento sobre el dataset total sea mejor, sin embargo, en el rendimiento respecto al conjunto de test poddemos observar como el modelo con la optimización de parámetros es mejor.\n",
    "\n",
    "### 2.c) Simplificación de modelo <a name=\"ej2-c\"> </a>\n",
    "Como hemos visto, el modelo se ajusta bastante bien al conjunto de datos, sin embargo, cuando representamos el árbol este es bastante extenso y dificil de comprender, por lo que vamos a estudiar si podemos disminuir la profundidad del árbol sin que afecte en exceso al rendimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 17\n",
    "\n",
    "res = [0, 0]\n",
    "\n",
    "for i in range(1, max_depth):\n",
    "    tree_aux = DecisionTreeClassifier(\n",
    "    criterion = 'entropy',\n",
    "    max_depth = i, \n",
    "    max_features = 'auto',\n",
    "    max_leaf_nodes = None, \n",
    "    min_impurity_decrease = 0.0, \n",
    "    min_samples_leaf = 8,\n",
    "    min_samples_split = 2)\n",
    "    scores = cross_val_score(tree_aux, X_data, y_data, scoring = \"accuracy\", cv = cross_validation)\n",
    "    res.append(scores.mean())\n",
    "plt.plot(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui podemos ver que a partir de profundidad 4 ya no se nota una mejora significativa, por lo que podemos representar este árbol que al tener menor profundidad se entenderá mejor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_depth5 = DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features='auto',\n",
    "    max_leaf_nodes=None, min_impurity_decrease=0.0, min_samples_leaf=8, min_samples_split=2)\n",
    "\n",
    "modelo_depth5.fit(X_data, y_data)\n",
    "\n",
    "export_graphviz(modelo_depth5, out_file='salida.dot', feature_names=dataset.columns, rounded=True, filled=True)\n",
    "with open(\"salida.dot\") as f:\n",
    "    grafo = f.read()\n",
    "graphviz.Source(grafo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.d) Árbol ID3<a name=\"ej2-d\"> </a>\n",
    "\n",
    "Todos los modelos que hemos desarrollado han sido utilizando el mismo algoritmo de aprendizaje de árboles de decisión que está incluido en *scikit_learn*, que es [CART](https://books.google.es/books/about/Classification_and_regression_trees.html?id=uxPvAAAAMAAJ&redir_esc=y), sin embargo, podemos utilizar otras librerias para utilizar otros algoritmos como los vistos en clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install decision-tree-id3\n",
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "from id3 import Id3Estimator\n",
    "\n",
    "modeloID3 = Id3Estimator()\n",
    "modeloID3.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction0 = modeloID3.predict(X_train)\n",
    "prediction1 = modeloID3.predict(X_test)\n",
    "prediction2 = modeloID3.predict(X_data)\n",
    "\n",
    "score0 = sum(x1==x2 for x1,x2 in zip(prediction0,y_train))/len(y_train)\n",
    "score1 = sum(x1==x2 for x1,x2 in zip(prediction1,y_test))/len(y_test)\n",
    "score2 = sum(x1==x2 for x1,x2 in zip(prediction2,y_data))/len(y_data)\n",
    "\n",
    "RESULTADOS.loc['modelo_ID3'] = [score0, score1, score2]\n",
    "RESULTADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: tarda varios minutos, se pueden reducir los parámetros para que tarde menos, o si se prefiere, \n",
    "# más abajo se detalla los parámetros óptimos obtenidos\n",
    "\n",
    "parametersID3 = {\n",
    "    'max_depth':[5, 10, 15],\n",
    "    'min_samples_split': [1, 5, 10, 20],\n",
    "    'prune' : [True, False],\n",
    "    'gain_ratio' : [True, False],\n",
    "    'min_entropy_decrease' : [0.0, 0.001, 0.01],\n",
    "    'is_repeating' : [True, False]\n",
    "}\n",
    "\n",
    "modeloID3_opt = GridSearchCV(Id3Estimator(), parametersID3, cv = cross_validation, scoring='accuracy')\n",
    "modeloID3_opt.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puede observarse, los mejores parámetros para el árbol ID3 son:\n",
    "<li> gain_ratio: True </li>\n",
    "<li> is_repeating: False </li>\n",
    "<li> max_depth: 10 </li>\n",
    "<li> min_entropy_decrease: 0.0 </li>\n",
    "<li> min_samples_split: 1 </li>\n",
    "<li> prune: False </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTADOS.loc['modelo_ID3_opt'] = [modeloID3_opt.score(X_train,y_train), modeloID3_opt.score(X_test,y_test), modeloID3_opt.score(X_data,y_data)]\n",
    "RESULTADOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puede verse, este algoritmo no ofrece un cambio significativo respecto a CART (posiblemente se aprecien más en datasets más complejos). Podemos representar este nuevo árbol para estudiar si es similar a los generados por el otro algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from id3 import export_graphviz #No confundir con el que estabamos usando antes \n",
    "\n",
    "export_graphviz(\n",
    "    modeloID3.tree_,\n",
    "    out_file = \"modeloID3.dot\",\n",
    "    feature_names=dataset.columns)\n",
    "with open(\"modeloID3.dot\") as f:\n",
    "    dot_grafo = f.read()\n",
    "graphviz.Source(dot_grafo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.e) Matriz de confusión <a name=\"ej2-e\"> </a>\n",
    "\n",
    "Hasta ahora hemos analizado el rendimiento en función de la relación entre número de aciertos y total, sin embargo, en un dataset de diabetes como el que estamos tratando es importante conocer que porcentaje de los aciertos son falsos positivos, porque no es lo mismo equivocarse prediciendo que el paciente tiene diabetes cuando no lo tiene que al reves.<br>\n",
    "Para ello vamos ha realizar una matriz de confusión con los datos del primer modelo de todos (podríamos hacerlo con cualquiera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = modelo.predict(X_data)\n",
    "\n",
    "c_matrix = confusion_matrix(y_data, y_pred)\n",
    "c_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta matriz de confusión puede ser representada mediante un mapa de calor con seaborn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(c_matrix, annot=True, fmt='d', cmap='Reds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.f) Otras métricas <a name=\"ej2-f\"> </a>\n",
    "\n",
    "otras métricas que podemos utilizar son la precisión, cobertura (_recall_), medida f1. Estas son métricas que dan diferente importancia al tipo de error (p.e. falsos positivos o falsos negativos en clasificación binaria). Pueden ser de utilidad para sistemas en los que nos preocupan más unos errores que otros.\n",
    "Además también podemos calcular dos medidas que evaluan el ratio entre true positive y false positive, estos son: TPR (_True Positive Rate_) y FPR (_False Positive Rate_).\n",
    "\n",
    "El significado intuitivo de las métricas es el siguiente:\n",
    "- _precision_: grado de acierto en las instancias propuestas como positivas (¿son todos los que están?)\n",
    "- _recall_: porcentaje de recuperación del total de las instancias positivas (¿están todos los que son?)\n",
    "- _f1_ : media armónica de precisión y cobertura.\n",
    "- _TPR_: positivos correctos (TP) dividido entre todos los positivos (TP+FN). También se denomina a esta métrica _sensibilidad_ y _cobertura_.\n",
    "- _FPR_: positivos erróneos (FP) dividido entre todos los negativos (FP+TN). A la métrica $1-FPR$ también se le denomina _especificidad_.\n",
    "\n",
    "Al combinar dos métricas complementarias, la medida _f1_ es apropiada para datasets que no estén bien balanceados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#True-negative (tn), false-positive(fp), false-negative(fn), true-positive(tp)\n",
    "tn, fp, fn, tp = c_matrix.ravel()\n",
    "\n",
    "precision = precision_score(y_data, y_pred, average='binary')\n",
    "print(\"precision: \", precision)\n",
    "\n",
    "recall = recall_score(y_data, y_pred, average='binary')\n",
    "print(\"recall: \", recall)\n",
    "\n",
    "f1 = f1_score(y_data, y_pred, average='binary')\n",
    "print(\"f1: \", f1)\n",
    "\n",
    "tpr = tp/(tp+fn)\n",
    "print(\"TPR: \", tpr)\n",
    "\n",
    "fpr = fp/(fp+tn)\n",
    "print(\"fpr: \", fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además de estas métricas, tambien podemos hacer un análisis ROC con los ratios calculados, cabe destacar que en el análisis ROC cuanto mayor es el area bajo la curva mejor es el rendimiento de nuestro modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = roc_curve(y_data, y_pred)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple vista puede observarse que el resultado es bastante bueno, pero podemos concretar la medida calculando el area bajo la curva:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = roc_auc_score(y_data, y_pred)\n",
    "print(\"area bajo la curva:\", area)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
